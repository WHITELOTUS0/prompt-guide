{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Managing Outputs with Output Parsers\n",
        "\n",
        "## Introduction\n",
        "\n",
        "While the language models can only generate textual outputs, a predictable data structure is always preferred in a production environment. For example, imagine you are creating a thesaurus application and want to generate a list of possible substitute words based on the context. The LLMs are powerful enough to generate many suggestions easily.Here is a sample output from the ChatGPT for several words with close meaning to the term “behavior.”\n",
        "\n",
        "```\n",
        "Here are some substitute words for \"behavior\":\n",
        "\n",
        "Conduct\n",
        "Manner\n",
        "Demeanor\n",
        "Attitude\n",
        "Disposition\n",
        "Deportment\n",
        "Etiquette\n",
        "Protocol\n",
        "Performance\n",
        "Actions\n",
        "\n",
        "```\n",
        "\n",
        "The problem is the lack of a method to extract relevant information from the mentioned string dynamically. You might say we can split the response by a new line and ignore the first two lines. However, there is no guarantee that the response have the same format every time. The list might be numbered, or there could be no introduction line.\n",
        "\n",
        "The Output Parsers help create a data structure to define the expectations from the output precisely. We can ask for a list of words in case of the word suggestion application or a combination of different variables like a word and the explanation of why it fits. The parser can extract the expected information for you."
      ],
      "metadata": {
        "id": "u8NQv6cluoo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Output Parsers\n",
        "There are three classes that we will introduce in this section. While the Pydrantic parser is the most powerful and flexible wrapper, knowing the other options for less complicated problems is beneficial. We will implement the thesaurus application in each section to better understand the details of each approach.\n",
        "\n",
        "### 1-1. PydanticOutputParser\n",
        "This class instructs the model to generate its output in a JSON format and then extract the information from the response. You will be able to treat the parser’s output as a list, meaning it will be possible to index through the results without worrying about formatting.\n",
        "\n",
        "This class uses the Pydantic library, which helps define and validate data structures in Python. It enables us to characterize the expected output with a name, type, and description. We need a variable that can store multiple suggestions in the thesaurus example. It can be easily done by defining a class that inherits from the Pydantic’s BaseModel class. Remember to install the required packages with the following command:"
      ],
      "metadata": {
        "id": "En7QlMQVvX9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-openai\n",
        "%pip install -qU langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0-YrLGiwFGC",
        "outputId": "f57604ed-dd8e-4cf5-ca91-822a4d13210e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/411.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m409.6/411.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/454.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.3/454.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field, field_validator\n",
        "from typing import List\n",
        "\n",
        "# Define your desired data structure.\n",
        "class Suggestions(BaseModel):\n",
        "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
        "\n",
        "    # Throw error in case of receiving a numbered-list from API\n",
        "    @field_validator('words')\n",
        "    def not_start_with_number(cls, field, info):\n",
        "        for item in field:\n",
        "            if item[0].isnumeric():\n",
        "                raise ValueError(\"The word can not start with numbers!\")\n",
        "        return field\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Suggestions)"
      ],
      "metadata": {
        "id": "rudvLX3Kws1R"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will pass the created class to the PydanticOutputParser wrapper to make it a LangChain parser object. The next step is to prepare the prompt."
      ],
      "metadata": {
        "id": "YpdRCT3sxr3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "Offer a list of suggestions to substitue the specified target_word based the presented context.\n",
        "{format_instructions}\n",
        "target_word={target_word}\n",
        "context={context}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"target_word\", \"context\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "model_input = prompt.format_prompt(\n",
        "\t\t\ttarget_word=\"behaviour\",\n",
        "\t\t\tcontext=\"The behaviour of the students in the classroom was disruptive and made it difficult for the teacher to conduct the lesson.\"\n",
        ")"
      ],
      "metadata": {
        "id": "HAEWeM18xsnz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Before executing the following code, make sure to have\n",
        "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "model = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.0)\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field, field_validator\n",
        "from typing import List\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "\n",
        "# Define your desired data structure.\n",
        "class Suggestions(BaseModel):\n",
        "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
        "\n",
        "    # Throw error in case of receiving a numbered-list from API\n",
        "    @field_validator('words')\n",
        "    def not_start_with_number(cls, field, info):\n",
        "        for item in field:\n",
        "            if item[0].isnumeric():\n",
        "                raise ValueError(\"The word can not start with numbers!\")\n",
        "        return field\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Suggestions)\n",
        "\n",
        "# set up the environment and model\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "model = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.0)\n",
        "\n",
        "\n",
        "template = \"\"\"\n",
        "Offer a list of suggestions to substitue the specified target_word based the presented context.\n",
        "{format_instructions}\n",
        "target_word={target_word}\n",
        "context={context}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"target_word\", \"context\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "\n",
        "model_input = prompt.format_prompt(\n",
        "\t\t\ttarget_word=\"behaviour\",\n",
        "\t\t\tcontext=\"The behaviour of the students in the classroom was disruptive and made it difficult for the teacher to conduct the lesson.\"\n",
        ")\n",
        "\n",
        "\n",
        "output = model.invoke(model_input.to_messages())\n",
        "\n",
        "parser.parse(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFPsay_fzPYH",
        "outputId": "859b3263-62ed-472a-a056-770fb39a645c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Suggestions(words=['conduct', 'action', 'demeanor', 'attitude', 'performance', 'manner', 'response', 'conduct', 'habits'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}